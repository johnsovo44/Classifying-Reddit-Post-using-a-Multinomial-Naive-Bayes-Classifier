{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3: Reddit Predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEFINE THE PROBLEM:\n",
    "\n",
    "Reddit servers have gone down and in the process subreddit post have gotten mixed up. We don't know what comes from where. A crack team of developers were able to fix the website and get it up and running again, organized and ready to go. They recruited a team of data scientist to help prevent this disorganization ever happening again. Their request: Based of the post and its references, can we predict where a post comes from? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GATHER THE DATA:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code to gather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data collection libraries\n",
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression as lr\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer \n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to pull subreddit posts\n",
    "def get_subreddit(url, n_pulls, headers):    \n",
    "\n",
    "    # Create empty templates\n",
    "    posts = []\n",
    "    after = None\n",
    "\n",
    "    # Create a loop that does max 25 requests per pull\n",
    "    for pull_num in range(n_pulls):\n",
    "        print(\"Pulling data attempted\", pull_num+1,\"time(s)\")\n",
    "\n",
    "        if after == None:\n",
    "            new_url = url                 # base case\n",
    "        else:\n",
    "            new_url = url+\"?after=\"+after # subsequent iterations\n",
    "\n",
    "        res = requests.get(new_url, headers=headers)\n",
    "\n",
    "        if res.status_code == 200:\n",
    "            subreddit_json = res.json()                      # Pull JSON\n",
    "            posts.extend(subreddit_json['data']['children']) # Get subreddit posts\n",
    "            after = subreddit_json['data']['after']          # 'after' = ID of the last post in this iteration\n",
    "        else:\n",
    "            print(\"We've run into an error. The status code is:\", res.status_code)\n",
    "            break\n",
    "\n",
    "        time.sleep(1)\n",
    "        \n",
    "    return(posts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in first subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pulling data attempted 1 time(s)\n",
      "Pulling data attempted 2 time(s)\n",
      "Pulling data attempted 3 time(s)\n",
      "Pulling data attempted 4 time(s)\n",
      "Pulling data attempted 5 time(s)\n",
      "Pulling data attempted 6 time(s)\n",
      "Pulling data attempted 7 time(s)\n",
      "Pulling data attempted 8 time(s)\n",
      "Pulling data attempted 9 time(s)\n",
      "Pulling data attempted 10 time(s)\n",
      "Pulling data attempted 11 time(s)\n",
      "Pulling data attempted 12 time(s)\n",
      "Pulling data attempted 13 time(s)\n",
      "Pulling data attempted 14 time(s)\n",
      "Pulling data attempted 15 time(s)\n",
      "Pulling data attempted 16 time(s)\n",
      "Pulling data attempted 17 time(s)\n",
      "Pulling data attempted 18 time(s)\n",
      "Pulling data attempted 19 time(s)\n",
      "Pulling data attempted 20 time(s)\n",
      "Pulling data attempted 21 time(s)\n",
      "Pulling data attempted 22 time(s)\n",
      "Pulling data attempted 23 time(s)\n",
      "Pulling data attempted 24 time(s)\n",
      "Pulling data attempted 25 time(s)\n",
      "Pulling data attempted 26 time(s)\n",
      "Pulling data attempted 27 time(s)\n",
      "Pulling data attempted 28 time(s)\n",
      "Pulling data attempted 29 time(s)\n",
      "Pulling data attempted 30 time(s)\n",
      "Pulling data attempted 31 time(s)\n",
      "Pulling data attempted 32 time(s)\n",
      "Pulling data attempted 33 time(s)\n",
      "Pulling data attempted 34 time(s)\n",
      "Pulling data attempted 35 time(s)\n",
      "Pulling data attempted 36 time(s)\n",
      "Pulling data attempted 37 time(s)\n",
      "Pulling data attempted 38 time(s)\n",
      "Pulling data attempted 39 time(s)\n",
      "Pulling data attempted 40 time(s)\n",
      "Pulling data attempted 41 time(s)\n",
      "Pulling data attempted 42 time(s)\n",
      "Pulling data attempted 43 time(s)\n"
     ]
    }
   ],
   "source": [
    "# Call function\n",
    "\n",
    "# Define URL and username\n",
    "url_name = \"https://www.reddit.com/r/politics.json\"\n",
    "username = {\"User-agent\": 'boom-deva'}      # header to prevent 429 error\n",
    "\n",
    "data = get_subreddit(url_name, n_pulls = 43, headers = username)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "data[0]['data']\n",
    "```\n",
    "We will have to make a for loop to get to the post into a \"dictionary\". It's type is a list. But it acts like a dictionary\n",
    "Above is an example of how to get the post. So make sure you are creating a data frame after you loop then from there\n",
    "make sure you are putting it in a dataframe after. Then do the same for your second reddit forum then join the two.\n",
    "Also keep track of how you will binarize the subreddits. One should receive 1 another 0. Create a new column after you\n",
    "make a data frame for the subreddit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i’m alan s. inouye, a registered lobbyist, and...</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>subpoena for mueller report and documents appr...</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sen. elizabeth warren will unveil a bill to ma...</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mueller testimony before congress ‘inevitable,...</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>american meritocracy is a myth - recent scanda...</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text subreddit\n",
       "0  i’m alan s. inouye, a registered lobbyist, and...  politics\n",
       "1  subpoena for mueller report and documents appr...  politics\n",
       "2  sen. elizabeth warren will unveil a bill to ma...  politics\n",
       "3  mueller testimony before congress ‘inevitable,...  politics\n",
       "4  american meritocracy is a myth - recent scanda...  politics"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subreddit_1 = {i:data[i][\"data\"][\"title\"].lower() for i in range(len(data))}\n",
    "subreddit_1 = pd.DataFrame.from_dict(subreddit_1, orient = 'index', columns = ['Text'])\n",
    "subreddit_1['subreddit'] = data[0]['data']['subreddit']\n",
    "subreddit_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddit_1.to_csv(\"Subreddit_1_Politics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Second subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pulling data attempted 1 time(s)\n",
      "Pulling data attempted 2 time(s)\n",
      "Pulling data attempted 3 time(s)\n",
      "Pulling data attempted 4 time(s)\n",
      "Pulling data attempted 5 time(s)\n",
      "Pulling data attempted 6 time(s)\n",
      "Pulling data attempted 7 time(s)\n",
      "Pulling data attempted 8 time(s)\n",
      "Pulling data attempted 9 time(s)\n",
      "Pulling data attempted 10 time(s)\n",
      "Pulling data attempted 11 time(s)\n",
      "Pulling data attempted 12 time(s)\n",
      "Pulling data attempted 13 time(s)\n",
      "Pulling data attempted 14 time(s)\n",
      "Pulling data attempted 15 time(s)\n",
      "Pulling data attempted 16 time(s)\n",
      "Pulling data attempted 17 time(s)\n",
      "Pulling data attempted 18 time(s)\n",
      "Pulling data attempted 19 time(s)\n",
      "Pulling data attempted 20 time(s)\n",
      "Pulling data attempted 21 time(s)\n",
      "Pulling data attempted 22 time(s)\n",
      "Pulling data attempted 23 time(s)\n",
      "Pulling data attempted 24 time(s)\n",
      "Pulling data attempted 25 time(s)\n",
      "Pulling data attempted 26 time(s)\n",
      "Pulling data attempted 27 time(s)\n",
      "Pulling data attempted 28 time(s)\n",
      "Pulling data attempted 29 time(s)\n",
      "Pulling data attempted 30 time(s)\n",
      "Pulling data attempted 31 time(s)\n",
      "Pulling data attempted 32 time(s)\n",
      "Pulling data attempted 33 time(s)\n",
      "Pulling data attempted 34 time(s)\n",
      "Pulling data attempted 35 time(s)\n",
      "Pulling data attempted 36 time(s)\n",
      "Pulling data attempted 37 time(s)\n",
      "Pulling data attempted 38 time(s)\n",
      "Pulling data attempted 39 time(s)\n",
      "Pulling data attempted 40 time(s)\n",
      "Pulling data attempted 41 time(s)\n",
      "Pulling data attempted 42 time(s)\n",
      "Pulling data attempted 43 time(s)\n"
     ]
    }
   ],
   "source": [
    "# Call function\n",
    "\n",
    "# Define URL and username\n",
    "url_name = \"https://www.reddit.com/r/stocks.json\"\n",
    "username = {\"User-agent\": 'boom-deva'}      # header to prevent 429 error\n",
    "\n",
    "data = get_subreddit(url_name, n_pulls = 43, headers = username)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rate my portfolio - r/stocks quarterly thread ...</td>\n",
       "      <td>stocks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>r/stocks daily discussion wednesday - apr 03, ...</td>\n",
       "      <td>stocks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>$750,000 to invest</td>\n",
       "      <td>stocks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what i learned this winter...</td>\n",
       "      <td>stocks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>amazon's giant 'dystopian' delivery-drone blim...</td>\n",
       "      <td>stocks</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text subreddit\n",
       "0  rate my portfolio - r/stocks quarterly thread ...    stocks\n",
       "1  r/stocks daily discussion wednesday - apr 03, ...    stocks\n",
       "2                                 $750,000 to invest    stocks\n",
       "3                      what i learned this winter...    stocks\n",
       "4  amazon's giant 'dystopian' delivery-drone blim...    stocks"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To clean the data I will put it into a corpus which is basically a data frame of documents (Text)\n",
    "subreddit_2 = {i:data[i][\"data\"][\"title\"].lower() for i in range(len(data))}\n",
    "subreddit_2 = pd.DataFrame.from_dict(subreddit_2, orient = 'index', columns = ['Text'])\n",
    "subreddit_2['subreddit'] = data[0]['data']['subreddit']\n",
    "subreddit_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddit_2.to_csv(\"Subreddit_2_Stocks\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
